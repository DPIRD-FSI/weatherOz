---
title: "Create Databases of BOM Station Locations"
output: github_document
---

  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r color, echo = FALSE, results='asis'}
# crayon needs to be explicitly activated in Rmd
options(crayon.enabled = TRUE)
# Hooks needs to be set to deal with outputs
# thanks to fansi logic
old_hooks <- fansi::set_knit_hooks(knitr::knit_hooks,
                                   which = c("output", "message", "error"))

library(data.table)
library(tidyverse)
```

This document provides details on methods used to create the database of BOM JSON files for stations and corresponding metadata, _e.g._, latitude, longitude (which are more detailed than what is in the JSON file), start, end, elevation, etc.

Refer to this BOM page for more reference, <http://reg.bom.gov.au/catalogue/anon-ftp.shtml>.

## Product code definitions

### States

  - IDD - NT

  - IDN - NSW/ACT

  - IDQ - Qld

  - IDS - SA
  
  - IDT - Tas/Antarctica (distinguished by the product number)
  
  - IDV - Vic
  
  - IDW - WA

### Product code numbers

  - 60701 - coastal observations (duplicated in 60801)
  
  - 60801 - State weather observations excluding Canberra
  
  - 60803 - Antarctica weather observations
  
  - 60901 - capital city weather observations (duplicated in 60801)
  
  - 60903 - Canberra area weather observations

## Get station metadata

The station metadata are downloaded from a zip file linked from the "[Bureau of Meteorology Site Numbers](http://www.bom.gov.au/climate/cdo/about/site-num.shtml)" website.
The zip file may be directly downloaded, [file of site details](ftp://ftp.bom.gov.au/anon2/home/ncc/metadata/sitelists/stations.zip).

```{r get_bom_station_data, eval=TRUE}
# This file is a pseudo-fixed width file. Line five contains the headers at
# fixed widths which are coded in the read_table() call.
# The last eight lines contain other information that we don't want.
# For some reason, reading it directly from the BOM website does not work, so
# we use curl to fetch it first and then import it from the R tempdir().

curl::curl_download(
  url = "ftp://ftp.bom.gov.au/anon2/home/ncc/metadata/sitelists/stations.zip",
  destfile = file.path(tempdir(), "stations.zip"),
  mode = "wb",
  quiet = TRUE
)
 utils::unzip(file.path(tempdir(), "stations.zip"), exdir = tempdir())
  file_in <- file.path(tempdir(), "stations.txt")

  bom_stations <-
    data.table::setDT(
      readr::read_fwf(
        file = file_in,
        na = c("..", ".....", " "),
        skip = 4,
        col_positions = readr::fwf_cols(
          "station_code" = c(1, 8),
          "dist" = c(9, 14),
          "station_name" = c(15, 55),
          "start" = c(56, 63),
          "end" = c(64, 71),
          "lat" = c(72, 80),
          "lon" = c(81, 90),
          "source" = c(91, 105),
          "state" = c(106, 109),
          "elev.m" = c(110, 120),
          "bar_height.m" = c(121, 129),
          "wmo" = c(130, 136)
        ),
        col_types = c(
          station_code = readr::col_character(),
          dist = readr::col_character(),
          site_name = readr::col_character(),
          start = readr::col_integer(),
          end = readr::col_integer(),
          lat = readr::col_double(),
          lon = readr::col_double(),
          source = readr::col_character(),
          state = readr::col_character(),
          elev.m = readr::col_double(),
          bar_height.m = readr::col_double(),
          wmo = readr::col_integer()
        ),
        n_max = length(utils::count.fields(file_in)) - 6,
        # drop last six rows
      )
    )

  bom_stations[, station_code := as.factor(station_code)]
  bom_stations[, station_name := DescTools::StrCap(x = station_name,
                                                   method = "word")]
  bom_stations[, start := as.integer(start)]
  bom_stations[, end := as.integer(end)]
  bom_stations[, status := ifelse(!is.na(end), "Closed", "Open")]
  bom_stations[is.na(end), end := as.integer(format(Sys.Date(), "%Y"))]
```

## Save data

### Station location database for get_ag_bulletin()

First, rename columns and drop a few that aren't necessary for the ag bulletin information.
Then pad the `site` field with 0 to match the data in the XML file that holds the ag bulletin information.
Lastly, create the data file for use in {weatherOz}.

```{r create-stations-site-list, message=FALSE}
new_stations_site_list <- data.table::data.table(bom_stations)

new_stations_site_list[, site :=
                         gsub("^0{1,2}", "", new_stations_site_list$site)]

data.table::setDT(new_stations_site_list)
data.table::setkey(new_stations_site_list, "station_code")
```

#### Changes in "stations_site_list"

```{r changes-stations-site-list, eval=FALSE}
load(system.file("extdata", "stations_site_list.rda", package = "weatherOz"))

(
  stations_site_list_changes <-
    diffobj::diffPrint(new_stations_site_list, stations_site_list)
)
```

#### Save stations_site_list Data and Changes

```{r save-stations-site-list}
if (!dir.exists("../inst/extdata")) {
  dir.create("../inst/extdata", recursive = TRUE)
}

stations_site_list <- new_stations_site_list

save(stations_site_list,
     file = "../inst/extdata/stations_site_list.rda",
     compress = "bzip2")

save(stations_site_list_changes,
     file = "../inst/extdata/stations_site_list_changes.rda",
     compress = "bzip2")
```

## Session Info

```{r session_info, echo=FALSE}
sessioninfo::session_info()
```
